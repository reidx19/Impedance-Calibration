{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Prep\n",
    "This notebook proceses the network to get it ready for impedance calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from shapely.ops import MultiLineString\n",
    "\n",
    "import modeling_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"fiona/ogrext.pyx\", line 136, in fiona.ogrext.gdal_open_vector\n",
      "  File \"fiona/_err.pyx\", line 291, in fiona._err.exc_wrap_pointer\n",
      "fiona._err.CPLE_AppDefinedError: malformed database schema (7): this file is a WAL-enabled database. It cannot be opened because it is presumably read-only or in a read-only directory.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/66/68r0k8s534v4gf9flsfnxnsr0000gn/T/ipykernel_72559/393575703.py\", line 9, in <module>\n",
      "    links = gpd.read_file(fp/'reconciled_network.gpkg',layer='links_w_signals_elevation')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 259, in _read_file\n",
      "    return _read_file_fiona(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/geopandas/io/file.py\", line 303, in _read_file_fiona\n",
      "    with reader(path_or_bytes, **kwargs) as features:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/fiona/env.py\", line 457, in wrapper\n",
      "    return f(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/fiona/__init__.py\", line 336, in open\n",
      "    colxn = Collection(\n",
      "            ^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/fiona/collection.py\", line 234, in __init__\n",
      "    self.session.start(self, **kwargs)\n",
      "  File \"fiona/ogrext.pyx\", line 587, in fiona.ogrext.Session.start\n",
      "  File \"fiona/ogrext.pyx\", line 143, in fiona.ogrext.gdal_open_vector\n",
      "fiona.errors.DriverError: malformed database schema (7): this file is a WAL-enabled database. It cannot be opened because it is presumably read-only or in a read-only directory.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1049, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1003, in get_records\n",
      "    lines, first = inspect.getsourcelines(etb.tb_frame)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/inspect.py\", line 1252, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tannerpassmore/mambaforge/envs/geo-env/lib/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "#fp = Path.home() / 'Documents/BikewaySimData/Projects/gdot/networks'\n",
    "fp = Path.home() / 'Library/CloudStorage/OneDrive-GeorgiaInstituteofTechnology/BikewaySim/Data'\n",
    "\n",
    "#bikewaysim_studyarea = gpd.read_file(Path.home()/'Documents/BikewaySimData/Data/Study Areas/bikewaysim_studyarea.geojson')\n",
    "\n",
    "#import network links\n",
    "#nodes = gpd.read_file(fp/'reconciled_network.gpkg',layer='nodes')\n",
    "#links = gpd.read_file(fp/'reconciled_network.gpkg',layer='links_w_signals_elevation',mask=bikewaysim_studyarea)\n",
    "links = gpd.read_file(fp/'reconciled_network.gpkg',layer='links_w_signals_elevation')\n",
    "\n",
    "#simply set all links to twoway\n",
    "links['oneway'] = False# links['oneway'] == \"1\"\n",
    "links['length_ft'] = links.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new link variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle seperation\n",
    "links.loc[(links['pbl']==1) | (links['mu']==1),'vehicle_separation'] = 3\n",
    "links.loc[links['bl'] == 1,'vehicle_separation'] = 2\n",
    "links.loc[links['vehicle_separation'].isna(),'vehicle_separation'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['linkid', 'A', 'B', 'osmid', 'link_type', 'name', 'highway', 'oneway',\n",
       "       'bearing', 'bridge', 'tunnel', 'bl', 'pbl', 'mu', 'speed_mph', 'lanes',\n",
       "       'fwd_azimuth', 'bck_azimuth', 'length', 'base_bearing', 'ST_NAME',\n",
       "       'functional_class', 'DIR_TRAVEL', 'speedlimit_range_mph',\n",
       "       'lanes_per_direction', 'FROM_LANES', 'TO_LANES', 'join_bearing',\n",
       "       'percent_overlap', 'bearing_diff', 'match name', 'name_check',\n",
       "       'overlap_check', 'bearing_check', 'final_check', 'signal_A', 'signal_B',\n",
       "       'rise_m', 'down_m', 'maxrise_m', 'minrise_m', 'up_grade', 'down_grade',\n",
       "       'max_grade', 'min_grade', 'geometry', 'length_ft',\n",
       "       'vehicle_separation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pseudo graph for modeling turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges, pseudo_df, pseudo_G = modeling_turns.create_pseudo_dual_graph(links,'A','B','linkid','oneway')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add desired attributes from links to df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['linkid', 'osmid', 'link_type', 'name', 'highway',\n",
    "       'bridge', 'tunnel', 'bl', 'pbl', 'mu','speedlimit_range_mph',\n",
    "       'lanes_per_direction', 'up_grade', 'down_grade', 'length_ft',\n",
    "       'vehicle_separation']\n",
    "df_edges = df_edges.merge(links[attrs],on='linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with grade\n",
    "Need to flip sign of grade for reverse links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges['up_grade'] = np.where(df_edges['reverse_link'], df_edges['down_grade'].abs(), df_edges['up_grade'])\n",
    "df_edges.drop(columns=['down_grade'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turns and Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add additional attributes needed for processing\n",
    "source_links = links[['linkid','osmid','link_type','name','highway']]\n",
    "target_links = links[['linkid','osmid','link_type','name','highway']]\n",
    "source_links.columns = 'source_' + source_links.columns\n",
    "target_links.columns = 'target_' + target_links.columns\n",
    "pseudo_df = pseudo_df.merge(source_links,on='source_linkid',how='left')\n",
    "pseudo_df = pseudo_df.merge(target_links,on='target_linkid',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn Restrictions\n",
    "Two types in OSM (represented as OSM relations):\n",
    "- No (blank) turns\n",
    "- Only this turn allowed\n",
    "\n",
    "For chosen we don't need to consider turn restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 turns removed\n"
     ]
    }
   ],
   "source": [
    "# turn_restrictions = pd.read_csv(fp.parent/'osm_turn_restrictions.csv')\n",
    "# pseudo_df = pseudo_df.merge(turn_restrictions,left_on=['source_osmid','target_osmid'],right_on=['from_way_id','to_way_id'],how='left')\n",
    "# road_cond = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "# no_restr = pseudo_df['type'] == 'no'\n",
    "# only_restr = pseudo_df['type'] == 'only'\n",
    "\n",
    "# #add a remove column\n",
    "# pseudo_df['remove'] = False\n",
    "\n",
    "# #remove the no turns\n",
    "# pseudo_df.loc[road_cond & no_restr,'remove'] = True\n",
    "\n",
    "# #for only, find all instances road_cond + from source and set to True\n",
    "# sources = set(turn_restrictions.loc[turn_restrictions['type']=='only','from_way_id'].tolist())\n",
    "# pseudo_df.loc[road_cond & pseudo_df['source_osmid'].isin(sources) & pseudo_df['type'].isna(),'remove'] = True\n",
    "\n",
    "# #Remove these turns and drop the added columns\n",
    "# print((pseudo_df['remove']==True).sum(),'turns removed')\n",
    "# pseudo_df = pseudo_df[pseudo_df['remove']==False]\n",
    "# pseudo_df.drop(columns=['relation_id', 'restriction', 'from_way_id',\n",
    "#        'to_way_id', 'type', 'remove'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with signals\n",
    "Perform two merges and use the source/target reverse link columns to determine which signal ID to keep.\n",
    "- For the source link, use signal_B if reverse == False else signal_A\n",
    "- For the target link, use signal_A if reverse == False else signal_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pseudo_df[['source_linkid','source_reverse_link']].merge(links,left_on='source_linkid',right_on='linkid',how='left')\n",
    "pseudo_df['source_signal'] = np.where(source['source_reverse_link'], source['signal_A'], source['signal_B'])\n",
    "\n",
    "target = pseudo_df[['target_linkid','target_reverse_link']].merge(links,left_on='target_linkid',right_on='linkid',how='left')\n",
    "pseudo_df['target_signal'] = np.where(target['target_reverse_link']==False, target['signal_A'], target['signal_B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying signalized/unsignalized turns\n",
    "- Only look at roads for now\n",
    "- Filter to left/right turns per source linkid per direction\n",
    "- Take the highest road classification and assign it as the cross street road classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_order = {\n",
    "    'trunk': 0,\n",
    "    'trunk_link': 1,\n",
    "    'primary': 2,\n",
    "    'primary_link': 3,\n",
    "    'secondary': 4,\n",
    "    'secondary_link': 5,\n",
    "    'tertiary': 6,\n",
    "    'tertiary_link': 7,\n",
    "    'unclassified': 8,\n",
    "    'residential': 9\n",
    "}\n",
    "highway_order = pd.Series(highway_order)\n",
    "highway_order = highway_order.reset_index()\n",
    "highway_order.columns = ['highway','order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add highway ranking based on the above\n",
    "pseudo_df['target_highway_order'] = pseudo_df['target_highway'].map(highway_order.set_index('highway')['order'])\n",
    "pseudo_df['source_highway_order'] = pseudo_df['source_highway'].map(highway_order.set_index('highway')['order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove straight and uturn\n",
    "cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "#only road to road for now\n",
    "cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "#use groupby to find the max target_highway order\n",
    "cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "cross_streets.name = 'cross_street'\n",
    "\n",
    "#add to main df\n",
    "pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "#change numbers back to normal\n",
    "pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalized = pseudo_df['source_signal'] == pseudo_df['target_signal']\n",
    "left_or_straight =  pseudo_df['turn_type'].isin(['left','straight'])\n",
    "both_road = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "cross_street = pseudo_df['cross_street_order'] <= 8\n",
    "\n",
    "pseudo_df.loc[signalized & left_or_straight & both_road,'signalized_left_straight'] = True\n",
    "pseudo_df.loc[pseudo_df['signalized_left_straight'].isna(),'signalized_left_straight'] = False\n",
    "\n",
    "pseudo_df.loc[-signalized & left_or_straight & both_road & cross_street,'unsignalized_left_straight_nonlocal'] = True\n",
    "pseudo_df.loc[pseudo_df['unsignalized_left_straight_nonlocal'].isna(),'unsignalized_left_straight_nonlocal'] = False\n",
    "\n",
    "#clean up\n",
    "rem =  ['source_osmid', 'source_link_type', 'source_name',\n",
    "       'source_highway', 'target_osmid', 'target_link_type', 'target_name',\n",
    "       'target_highway', 'source_signal', 'target_signal',\n",
    "       'target_highway_order', 'source_highway_order', 'cross_street',\n",
    "       'cross_street_order']\n",
    "pseudo_df.drop(columns=rem,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for impedance calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (fp.parent / 'impedance_calibration.pkl').open('wb') as fh:\n",
    "    export = (df_edges,pseudo_df,pseudo_G)\n",
    "    pickle.dump(export,fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add geometry to examine results in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add geo\n",
    "link_geo = dict(zip(links['linkid'],links['geometry']))\n",
    "pseudo_df['src_geo'] = pseudo_df['source_linkid'].map(link_geo)\n",
    "pseudo_df['trgt_geo'] = pseudo_df['target_linkid'].map(link_geo)\n",
    "pseudo_df['geometry'] = pseudo_df[['src_geo','trgt_geo']].apply(lambda row: MultiLineString([row['src_geo'],row['trgt_geo']]),axis=1)\n",
    "\n",
    "pseudo_df.drop(columns=['src_geo','trgt_geo'],inplace=True)\n",
    "pseudo_df = gpd.GeoDataFrame(pseudo_df,crs=links.crs)\n",
    "\n",
    "pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "\n",
    "#check results (may need a smaller road network to test on)\n",
    "pseudo_df.to_file(Path.home()/'Downloads/testing.gpkg',layer='cross_streets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
