{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impedance Calibration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import modeling_turns\n",
    "from stochopy.optimize import minimize\n",
    "from stochastic_optimization import objective_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Path.home() / 'Documents/BikewaySimData/Projects/gdot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import network links\n",
    "nodes = gpd.read_file(fp/\"networks/reconciled_network.gpkg\",layer='nodes')\n",
    "links = gpd.read_file(fp/\"networks/reconciled_network.gpkg\",layer='links_w_signals_elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change oneway back to true/false (it saves as a str)\n",
    "links['oneway'] = links['oneway'] == '1'\n",
    "\n",
    "#recalculate link lengths\n",
    "links['length_ft'] = links.length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impedance Function 2\n",
    "- Link Specific:\n",
    "    - Average Grade (%grade)\n",
    "    - Vehicle Seperation from OSM/ARC Inventory (1 = None, 2 = Bike Lane, 3 = MUP/Curb protected bike lanes)\n",
    "    - Number of lanes from HERE ()\n",
    "- Turn Specific\n",
    "    - Unsignalized left/straight across roads with higher than tertiary classification (0 or 1)\n",
    "    - Signalized intersection left/straight (0 or 1)\n",
    "\n",
    "## Applying Link Costs\n",
    "---\n",
    "Dict keys must correspond to column names in links GeoDataFrame. Multiple dicts can be passed to pseudo_df the impacts of changing impedances. The links cost function is of this format:\n",
    "$$ C_e = \\frac{l_e*60^2}{s*5280} * (1-\\sum \\beta_i x_{i,e}) $$\n",
    "\n",
    "where:\n",
    "- $e$ is an edge/link in network graph $G$ with V vertices/nodes and E edges/links\n",
    "- $l_e$ is the length of the link in feet\n",
    "- $\\beta$ is the impedance coefficient for attribute $i$\n",
    "- $X_{i,e}$ is the value of attribute $i$ for link $e$\n",
    "- $s$ is the assumed average speed of the cyclist in mph\n",
    "\n",
    "Notes:\n",
    "- Negative attributes **decrease** impedance  \n",
    "- Positive attributes **increase** impedance\n",
    "- **Negative link costs are not allowed**\n",
    "- Time to traverse a link has already been calculated in the prepare_network function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pseudo graph for modeling turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_A</th>\n",
       "      <th>source_B</th>\n",
       "      <th>target_A</th>\n",
       "      <th>target_B</th>\n",
       "      <th>source_linkid</th>\n",
       "      <th>source_azimuth</th>\n",
       "      <th>source_reverse_link</th>\n",
       "      <th>target_linkid</th>\n",
       "      <th>target_azimuth</th>\n",
       "      <th>target_reverse_link</th>\n",
       "      <th>azimuth_change</th>\n",
       "      <th>turn_type</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301267</th>\n",
       "      <td>1581270385</td>\n",
       "      <td>1581270420</td>\n",
       "      <td>1581270420</td>\n",
       "      <td>69430434</td>\n",
       "      <td>54818.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>False</td>\n",
       "      <td>46430.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>True</td>\n",
       "      <td>225.6</td>\n",
       "      <td>left</td>\n",
       "      <td>(1581270385, 1581270420)</td>\n",
       "      <td>(1581270420, 69430434)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301270</th>\n",
       "      <td>1581270385</td>\n",
       "      <td>1581270420</td>\n",
       "      <td>1581270420</td>\n",
       "      <td>2909454241</td>\n",
       "      <td>54818.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>False</td>\n",
       "      <td>47571.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>True</td>\n",
       "      <td>45.6</td>\n",
       "      <td>right</td>\n",
       "      <td>(1581270385, 1581270420)</td>\n",
       "      <td>(1581270420, 2909454241)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_A    source_B    target_A    target_B  source_linkid  \\\n",
       "301267  1581270385  1581270420  1581270420    69430434        54818.0   \n",
       "301270  1581270385  1581270420  1581270420  2909454241        54818.0   \n",
       "\n",
       "        source_azimuth  source_reverse_link  target_linkid  target_azimuth  \\\n",
       "301267            33.4                False        46430.0           259.0   \n",
       "301270            33.4                False        47571.0            79.0   \n",
       "\n",
       "        target_reverse_link  azimuth_change turn_type  \\\n",
       "301267                 True           225.6      left   \n",
       "301270                 True            45.6     right   \n",
       "\n",
       "                          source                    target  \n",
       "301267  (1581270385, 1581270420)    (1581270420, 69430434)  \n",
       "301270  (1581270385, 1581270420)  (1581270420, 2909454241)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_df[pseudo_df['source_linkid']==54818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    238631\n",
       "True        249\n",
       "Name: remove, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_df['remove'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['linkid','link_type','highway',\n",
    "         'vehicle_separation','speedlimit_range_mph',\n",
    "         'lanes_per_direction','up_grade','down_grade','length_ft']\n",
    "df_edges = df_edges.merge(links[attrs],on='linkid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with signals\n",
    "Perform two merges and use the source/target reverse link columns to determine which signal ID to keep.\n",
    "- For the source link, use signal_B if reverse == False else signal_A\n",
    "- For the target link, use signal_A if reverse == False else signal_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pseudo_df[['source_linkid','source_reverse_link']].merge(links,left_on='source_linkid',right_on='linkid',how='left')\n",
    "pseudo_df['source_signal'] = np.where(source['source_reverse_link'], source['signal_A'], source['signal_B'])\n",
    "\n",
    "target = pseudo_df[['target_linkid','target_reverse_link']].merge(links,left_on='target_linkid',right_on='linkid',how='left')\n",
    "pseudo_df['target_signal'] = np.where(target['target_reverse_link']==False, target['signal_A'], target['signal_B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding cross streets\n",
    "- Only look at roads for now\n",
    "- Filter to left/right turns per source linkid per direction\n",
    "- Take the highest road classification and assign it as the cross street road classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_order = {\n",
    "    'trunk': 0,\n",
    "    'trunk_link': 1,\n",
    "    'primary': 2,\n",
    "    'primary_link': 3,\n",
    "    'secondary': 4,\n",
    "    'secondary_link': 5,\n",
    "    'tertiary': 6,\n",
    "    'tertiary_link': 7,\n",
    "    'unclassified': 8,\n",
    "    'residential': 9\n",
    "}\n",
    "highway_order = pd.Series(highway_order)\n",
    "highway_order = highway_order.reset_index()\n",
    "highway_order.columns = ['highway','order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo_df = pd.merge(pseudo_df,source_attr,left_on='source_linkid',right_index=True,how='left')\n",
    "# pseudo_df = pd.merge(pseudo_df,target_attr,left_on='target_linkid',right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove straight and backwards\n",
    "cond1 = pseudo_df['turn_type'].isin(['left','right'])\n",
    "#only road to road for now\n",
    "cond2 = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "cross_streets = pseudo_df[cond1 & cond2]\n",
    "\n",
    "#use groupby to find the max target_highway order\n",
    "cross_streets = cross_streets.groupby(['source_linkid','source_A','source_B'])['target_highway_order'].min()\n",
    "cross_streets.name = 'cross_street'\n",
    "\n",
    "#add to main df\n",
    "pseudo_df = pd.merge(pseudo_df,cross_streets,left_on=['source_linkid','source_A','source_B'],right_index=True,how='left')\n",
    "\n",
    "#change numbers back to normal\n",
    "pseudo_df['cross_street_order'] = pseudo_df['cross_street']\n",
    "pseudo_df['cross_street'] = pseudo_df['cross_street'].map(highway_order.set_index('order')['highway'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify signalized/unsiganlized turns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "signalized = pseudo_df['source_signal'] == pseudo_df['target_signal']\n",
    "left_or_straight =  pseudo_df['turn_type'].isin(['left','straight'])\n",
    "both_road = (pseudo_df['source_link_type'] == 'road') & (pseudo_df['target_link_type'] == 'road')\n",
    "cross_street = pseudo_df['cross_street_order'] <= 8\n",
    "\n",
    "pseudo_df.loc[signalized & left_or_straight & both_road,'signalized_left_straight'] = True\n",
    "pseudo_df.loc[pseudo_df['signalized_left_straight'].isna(),'signalized_left_straight'] = False\n",
    "\n",
    "pseudo_df.loc[-signalized & left_or_straight & both_road & cross_street,'unsignalized_left_straight_nonlocal'] = True\n",
    "pseudo_df.loc[pseudo_df['unsignalized_left_straight_nonlocal'].isna(),'unsignalized_left_straight_nonlocal'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import MultiLineString\n",
    "\n",
    "#add geo\n",
    "link_geo = dict(zip(links['linkid'],links['geometry']))\n",
    "pseudo_df['src_geo'] = pseudo_df['source_linkid'].map(link_geo)\n",
    "pseudo_df['trgt_geo'] = pseudo_df['target_linkid'].map(link_geo)\n",
    "pseudo_df['geometry'] = pseudo_df[['src_geo','trgt_geo']].apply(lambda row: MultiLineString([row['src_geo'],row['trgt_geo']]),axis=1)\n",
    "\n",
    "pseudo_df.drop(columns=['src_geo','trgt_geo'],inplace=True)\n",
    "pseudo_df = gpd.GeoDataFrame(pseudo_df,crs=links.crs)\n",
    "\n",
    "pseudo_df['source'] = pseudo_df['source'].astype(str)\n",
    "pseudo_df['target'] = pseudo_df['target'].astype(str)\n",
    "\n",
    "#check results (may need a smaller road network to test on)\n",
    "pseudo_df.to_file(Path.home()/'Downloads/testing.gpkg',layer='cross_streets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have position of beta next to name of variable\n",
    "beta_links = {\n",
    "    0 : 'up_grade',\n",
    "    1 : 'vehicle_separation',\n",
    "    2 : 'speedlimit'\n",
    "}\n",
    "\n",
    "beta_turns = {\n",
    "    3 : 'signalized_left_straight',\n",
    "    4 : 'unsignalized_left_straight_nonlocal'\n",
    "}\n",
    "\n",
    "#customize this function to change impedance formula\n",
    "#TODO streamline process of trying out new impedance functions\n",
    "def link_impedance_function(betas,beta_links,links):\n",
    "    #prevent mutating the original links gdf\n",
    "    links = links.copy()\n",
    "    \n",
    "    links['attr_multiplier'] = 0\n",
    "\n",
    "    for key, item in beta_links.items():\n",
    "        links['attr_mulitplier'] = links['attr_mulitplier'] + (betas[key] * links[item])\n",
    "\n",
    "    links['link_cost'] = links['length_ft'] * (1 + links['attr_multiplier'])\n",
    "    return links\n",
    "\n",
    "def turn_impedance_function(betas,beta_turns,pseudo_df):\n",
    "    #use beta coefficient to calculate turn cost\n",
    "    base_turn_cost = 30 # from Lowry et al 2016 DOI: http://dx.doi.org/10.1016/j.tra.2016.02.003\n",
    "    # turn_costs = {\n",
    "    #     'left': betas[1] * base_turn_cost,\n",
    "    #     'right': betas[1] * base_turn_cost,\n",
    "    #     'straight': betas[1] * base_turn_cost\n",
    "    # }\n",
    "    #pseudo_df['turn_cost'] = pseudo_df['turn_type'].map(turn_costs)\n",
    "\n",
    "    pseudo_df = pseudo_df.copy()\n",
    "\n",
    "    pseudo_df['attr_multiplier'] = 0\n",
    "\n",
    "    for key, item in beta_turns.items():\n",
    "        pseudo_df['attr_multiplier'] = links\n",
    "\n",
    "\n",
    "    return pseudo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% prepare link dataframe\n",
    "links['bike'] = links['bl'] + links['pbl'] + links['mu']\n",
    "links['bike'] = links['bike'] >= 1\n",
    "\n",
    "cost_columns = ['linkid','bike','length_ft']#,'up-grade','down-grade','length_ft']\n",
    "df_edges = df_edges.merge(links[cost_columns],on='linkid')\n",
    "\n",
    "# df_edges['grade'] = np.nan\n",
    "# df_edges.loc[df_edges['reverse_link'],'grade'] = df_edges['down-grade']\n",
    "# df_edges.loc[~df_edges['reverse_link'],'grade'] = df_edges['up-grade']\n",
    "# #ignore downs\n",
    "# df_edges.loc[df_edges['grade']<0,'grade'] = 0\n",
    "# df_edges.drop(columns=['up-grade','down-grade','bearing'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matched traces\n",
    "export_fp = Path.home() / 'Documents/BikewaySimData/Projects/gdot/gps_traces'\n",
    "\n",
    "import pickle\n",
    "with (export_fp/'test_matches.pkl').open('rb') as fh:\n",
    "    matched_traces = pickle.load(fh)\n",
    "matched_traces\n",
    "\n",
    "#matched_traces = gpd.read_file(export_fp/'test_matches.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_traces['linkids'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix set\n",
    "import ast\n",
    "matched_traces['linkids'] = matched_traces['linkids'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop loops\n",
    "matched_traces = matched_traces.loc[matched_traces['start']!=matched_traces['end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (df_edges,pseudo_df,pseudo_G,matched_traces,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stochastic_optimization\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = 68294161\n",
    "# target = 2400730083\n",
    "\n",
    "# pseudo_G, virtual_edges = modeling_turns.add_virtual_links(pseudo_df,pseudo_G,source,[target])   \n",
    "\n",
    "# virtual_edges\n",
    "\n",
    "# pseudo_G.out_edges(target)\n",
    "# #pseudo_G.in_edges((5416154182, 2400730083))\n",
    "\n",
    "# list(pseudo_G.in_edges(target))[0]\n",
    "\n",
    "# test = nx.ego_graph(pseudo_G,source,4)\n",
    "# test.edges()\n",
    "\n",
    "# import networkx as nx\n",
    "# test_target = (5318092552,5416166514)\n",
    "\n",
    "# length, node_list = nx.single_source_dijkstra(pseudo_G,source,test_target,weight='weight')\n",
    "# node_list\n",
    "\n",
    "# pseudo_G = modeling_turns.remove_virtual_edges(pseudo_G,virtual_edges)\n",
    "\n",
    "# import stochastic_optimization\n",
    "# from importlib import reload\n",
    "# reload(stochastic_optimization)\n",
    "# reload(modeling_turns)\n",
    "\n",
    "# betas = [1.14593853, 0.60739776]\n",
    "# val, merged = stochastic_optimization.objective_function(betas,*args)\n",
    "\n",
    "# merged[1].set_geometry('geometry_modeled').set_crs('epsg:2240').explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 68175462\n",
    "target = 69214484\n",
    "\n",
    "import networkx as nx\n",
    "nx.single_source_dijkstra(pseudo_G,source,target,weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stochastic_optimization\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "start = time.time()\n",
    "bounds = [[0,5],[0,5]]\n",
    "x = minimize(stochastic_optimization.objective_function, bounds, args=args, method='pso')\n",
    "end = time.time()\n",
    "print(f'Took {(end-start)/60/60} hours')\n",
    "#results[segment_filepath] = (x.x,x.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to re-create routes using the coefficients so we can do vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stochastic_optimization\n",
    "from importlib import reload\n",
    "reload(stochastic_optimization)\n",
    "\n",
    "betas = np.array([0.09231109, 2.35131751])\n",
    "args = (df_edges,pseudo_df,pseudo_G,matched_traces,False,True)\n",
    "test = stochastic_optimization.objective_function(betas,*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns\n",
    "\n",
    "\n",
    "test['percent_detour'] = (((test['length_ft']-test['shortest_length_ft'])/test['shortest_length_ft'])*100).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trip_and_user = pd.read_pickle(export_fp/'trip_and_user.pkl')\n",
    "\n",
    "test_merge = test.merge(trip_and_user,on='tripid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripid = test.loc[test['overlap']<0.2,'tripid'].sample(1).item()\n",
    "tripid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['starttime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas as gpd\n",
    "from folium.plugins import MarkerCluster, PolyLineTextPath\n",
    "from folium.map import FeatureGroup\n",
    "\n",
    "def visualize(test_merge,tripid):\n",
    "\n",
    "\n",
    "     gdf = test_merge.copy()\n",
    "\n",
    "     gdf.set_geometry(\"geometry\",inplace=True)\n",
    "     gdf.set_crs(\"epsg:2240\",inplace=True)\n",
    "\n",
    "     # Your GeoDataFrames\n",
    "     chosen_path = gdf.loc[gdf['tripid']==tripid,['tripid','geometry']]\n",
    "     shortest_path = gdf.loc[gdf['tripid']==tripid,['tripid','shortest_geo']].set_geometry('shortest_geo').set_crs(gdf.crs)\n",
    "     intersection = gdf.loc[gdf['tripid']==tripid,['tripid','shortest_intersect_geo']].set_geometry('shortest_intersect_geo').set_crs(gdf.crs)\n",
    "     modeled_path = gdf.loc[gdf['tripid']==tripid,['tripid','geometry_modeled']].set_geometry('geometry_modeled').set_crs(gdf.crs)\n",
    "\n",
    "     #start point\n",
    "     start_N = gdf.loc[gdf['tripid']==tripid,'start'].item()\n",
    "     start_pt = nodes.to_crs('epsg:4326').loc[nodes['N']==start_N,'geometry'].item()\n",
    "\n",
    "     #end point\n",
    "     end_N = gdf.loc[gdf['tripid']==tripid,'end'].item()\n",
    "     end_pt = nodes.to_crs('epsg:4326').loc[nodes['N']==end_N,'geometry'].item()\n",
    "\n",
    "     # reproj\n",
    "     x_mean = chosen_path.to_crs(epsg='4326').geometry.item().centroid.x\n",
    "     y_mean = chosen_path.to_crs(epsg='4326').geometry.item().centroid.y\n",
    "\n",
    "     # Create a Folium map centered around the mean of the GPS points\n",
    "     center = [y_mean,x_mean-.04]\n",
    "     mymap = folium.Map(location=center, zoom_start=13)\n",
    "\n",
    "     # Convert GeoDataFrames to GeoJSON\n",
    "     chosen_path_geojson = chosen_path.to_crs(epsg='4326').to_json()\n",
    "     shortest_path_geojson = shortest_path.to_crs(epsg='4326').to_json()\n",
    "     intersection_geojson = intersection.to_crs(epsg='4326').to_json()\n",
    "     modeled_path_geojson = modeled_path.to_crs(epsg='4326').to_json()\n",
    "\n",
    "     # Create FeatureGroups for each GeoDataFrame\n",
    "     chosen_path_fg = FeatureGroup(name='Chosen Path')\n",
    "     shortest_path_fg = FeatureGroup(name='Shortest Path')\n",
    "     intersection_fg = FeatureGroup(name='Buffer Intersection',show=False)\n",
    "     modeled_path_fg = FeatureGroup(name='Modeled Path')\n",
    "\n",
    "     # Add GeoJSON data to FeatureGroups\n",
    "     folium.GeoJson(chosen_path_geojson, name='Chosen Path',\n",
    "                    style_function=lambda x: {'color': '#fc8d62', 'weight': 12}).add_to(chosen_path_fg)\n",
    "     folium.GeoJson(shortest_path_geojson, name='Shortest Path',\n",
    "                    style_function=lambda x: {'color': '#66c2a5', 'weight': 8}).add_to(shortest_path_fg)\n",
    "     folium.GeoJson(intersection_geojson, name='Buffer Intersection',\n",
    "                    style_function=lambda x: {'color':\"gray\",'fillColor':\"#ffff00\",\"fillOpacity\": 0.75}).add_to(intersection_fg)\n",
    "     folium.GeoJson(modeled_path_geojson, name='Modeled Path',\n",
    "                    style_function=lambda x: {'color': '#8da0cb','weight': 8}).add_to(modeled_path_fg)\n",
    "\n",
    "     # Add FeatureGroups to the map\n",
    "     chosen_path_fg.add_to(mymap)\n",
    "     shortest_path_fg.add_to(mymap)\n",
    "     intersection_fg.add_to(mymap)\n",
    "     modeled_path_fg.add_to(mymap)\n",
    "\n",
    "     # Add start and end points with play and stop buttons\n",
    "     start_icon = folium.Icon(color='green',icon='play',prefix='fa')\n",
    "     end_icon = folium.Icon(color='red',icon='stop',prefix='fa')\n",
    "     folium.Marker(location=[start_pt.y, start_pt.x],icon=start_icon).add_to(mymap)\n",
    "     folium.Marker(location=[end_pt.y, end_pt.x],icon=end_icon).add_to(mymap)\n",
    "\n",
    "     # Add layer control to toggle layers on/off\n",
    "     folium.LayerControl().add_to(mymap)\n",
    "\n",
    "     #retrive overlap\n",
    "     # exact_overlap = gdf.loc[gdf['tripid']==tripid,'shortest_exact_overlap_prop'].item()\n",
    "     # buffer_overlap = gdf.loc[gdf['tripid']==tripid,'shortest_buffer_overlap'].item()\n",
    "     row = gdf.loc[gdf['tripid']==tripid].squeeze()\n",
    "\n",
    "     # Add legend with statistics\n",
    "     #TODO what happened to duration\n",
    "     legend_html = f'''\n",
    "          <div style=\"position: fixed; \n",
    "                    bottom: 5px; left: 5px; width: 300px; height: 400px; \n",
    "                    border:2px solid grey; z-index:9999; font-size:14px;\n",
    "                    background-color: white;\n",
    "                    opacity: 0.9;\">\n",
    "          &nbsp; <b>Trip ID: {tripid}, User ID: {row['userid']}</b> <br>\n",
    "          &nbsp; <b> Date: {row['starttime']} </b> <br>\n",
    "          &nbsp; Start Point &nbsp; <i class=\"fa fa-play\" style=\"color:green\"></i>,\n",
    "          End Point &nbsp; <i class=\"fa fa-stop\" style=\"color:red\"></i> <br>\n",
    "          \n",
    "          &nbsp; Chosen Path &nbsp; <div style=\"width: 20px; height: 5px; background-color: #fc8d62; display: inline-block;\"></div> <br>\n",
    "          &nbsp; Shortest Path &nbsp; <div style=\"width: 20px; height: 5px; background-color: #66c2a5; display: inline-block;\"></div> <br>\n",
    "          &nbsp; Modeled Path &nbsp; <div style=\"width: 20px; height: 5px; background-color: #8da0cb; display: inline-block;\"></div> <br>\n",
    "          &nbsp; Buffer Overlap &nbsp; <div style=\"width: 20px; height: 10px; background-color: #ffff00; display: inline-block;\"></div> <br>\n",
    "\n",
    "          &nbsp; Percent Detour: {row['percent_detour']:.0f}% <br>\n",
    "          &nbsp; Shortest Path Overlap: {row['shortest_buffer_overlap']*100:.0f}% <br>\n",
    "          &nbsp; Modeled Path Overlap: {row['overlap']*100:.0f}% <br>\n",
    "          &nbsp; Trip Type: {row['trip_type']} <br>\n",
    "          &nbsp; Length (mi): {row['length_ft']/5280:.0f} <br>\n",
    "          &nbsp; Age: {row['age']} <br>\n",
    "          &nbsp; Gender: {row['gender']} <br>\n",
    "          &nbsp; Income: {row['income']} <br>\n",
    "          &nbsp; Ethnicity: {row['ethnicity']} <br>\n",
    "          &nbsp; Cycling Frequency: {row['cyclingfreq']} <br>\n",
    "          &nbsp; Rider History: {row['rider_history']} <br>\n",
    "          &nbsp; Rider Type: {row['rider_type']} <br><br>\n",
    "\n",
    "          </div>\n",
    "          '''\n",
    "     mymap.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "     # Save the map to an HTML file or display it in a Jupyter notebook\n",
    "     #mymap.save('map.html')\n",
    "     # mymap.save('/path/to/save/map.html')  # Use an absolute path if needed\n",
    "     return mymap  # Uncomment if you are using Jupyter notebook\n",
    "\n",
    "     #TODO add in the legend with trip info and then we're golden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.tripid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tripid = 891#30000\n",
    "tripid = 7257#9806#891\n",
    "mymap = visualize(test_merge,tripid)\n",
    "mymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random two points appears to work fine\n",
    "#im thinking it has something to do with the virtual edges?\n",
    "\n",
    "import random\n",
    "            source = random.choice(list(pseudo_G.nodes()))\n",
    "            target = random.choice(list(pseudo_G.nodes()))\n",
    "            length, node_list = nx.single_source_dijkstra(pseudo_G,source,target,weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if ~pseudo_G.has_node(source):\n",
    "        #     start_coord = trips_df.loc[trips_df['o']==source,['start_lat','start_lon']].iloc[0]\n",
    "        #     start_coord['geometry'] = Point(start_coord.iloc[0,1],start_coord.iloc[0,0])\n",
    "        #     start_coord = gpd.GeoDataFrame(start_coord,geometry='geometry',crs='epsg:4326')\n",
    "        #     start_coord.to_crs(nodes.crs)\n",
    "        #     source = gpd.sjoin_nearest(start_coord, nodes)['N'].item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
